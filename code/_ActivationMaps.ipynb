{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a832202e",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "38b10cbb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib.request\n",
    "from pathlib import Path\n",
    "import PIL\n",
    "from PIL import Image\n",
    "import cv2\n",
    "from IPython.display import Image\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cbf2e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "    ###################################################################\n",
    "    from keract import display_activations\n",
    "    # The image path\n",
    "    img_path = '../data/Yoga-82/YOGA_downloads_withoutClipart/Akarna_Dhanurasana/40.jpg'\n",
    "    # Preprocessing the image for the model\n",
    "    x = preprocess_image(img_path=img_path,model=model,resize=target_size)\n",
    "    # Generate the activations \n",
    "    activations = get_activations(model, x)\n",
    "    ###################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e4d26e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_img(df):\n",
    "    num = df.shape[0]\n",
    "    \n",
    "    data = np.zeros((num,224,224,3),dtype='float32')\n",
    "\n",
    "    for i in range(num):\n",
    "        path = df['YogaPoses'].iloc[i] + '/' + df['ImageNumbers'].iloc[i]\n",
    "        img_path = '../data/Yoga-82/YOGA_downloads_withoutClipart/'\n",
    "        imgs = img_path + path\n",
    "        \n",
    "        \n",
    "        image = Image.open(imgs).convert(\"RGB\")\n",
    "        image = image.resize((224,224), Image.ANTIALIAS)\n",
    "        data[i][:][:][:] = image\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ca2195",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from keract import display_activations\n",
    "from keract import get_activations\n",
    "\n",
    "\n",
    "# The image path\n",
    "#img_path = '../data/Yoga-82/YOGA_downloads_withoutClipart/Akarna_Dhanurasana/40.jpg'\n",
    "# Preprocessing the image for the model\n",
    "x = process_img(Activation_df)\n",
    "# Generate the activations \n",
    "model = dense201_hirar_new()\n",
    "activations = get_activations(model, x)\n",
    "display_activations(activations, save=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece0a04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_df = pd.read_csv(path+'CSVLogger_hirarnew.csv')\n",
    "log_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5190a65c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def correctLabels_82(classification_report82_V1):\n",
    "    classification_report82_V1 = class_report(path + 'classification_report82.csv').reset_index(drop=True)\n",
    "    classification_report82_V1['index1'] = classification_report82_V1.index\n",
    "    classification_report82_V1 = classification_report82_V1.replace({\"index1\": trans82})\n",
    "    classification_report82_V1.iloc[-3:, classification_report82_V1.columns.get_loc('index1')] = ['accuracy', 'macro avg', 'weighted avg']\n",
    "    classification_report82_V1 = classification_report82_V1.set_index('index1')\n",
    "    return classification_report82_V1\n",
    "\n",
    "#class report as pandas df\n",
    "def class_report(path):\n",
    "    report= pd.read_csv(path).T\n",
    "    report.columns = report.iloc[0]\n",
    "    report.drop(index=report.index[0], axis=0, inplace=True)\n",
    "    report.columns.name = None\n",
    "\n",
    "    return report\n",
    "\n",
    "path = '../Results/dense201_hirar_new/'\n",
    "classification_reportV3_6 = class_report(path + 'classification_report6.csv')\n",
    "classification_reportV3_6   #0.219512\n",
    "\n",
    "#classification_reportV3_20 = class_report(path + 'classification_report20.csv') \n",
    "#classification_reportV3_20 # 0.036585\n",
    "#classification_report82_V3 = correctLabels_82(class_report(path + 'classification_report82.csv'))\n",
    "#classification_report82_V3 #0,012195"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "068e08d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "func_model = dense201_hirar_6same20()\n",
    "\n",
    "\n",
    "class GradCAM:\n",
    "    def __init__(self, model, classIdx, layerName=None):\n",
    "        # store the model, the class index used to measure the class\n",
    "        # activation map, and the layer to be used when visualizing\n",
    "        # the class activation map\n",
    "        self.model = model\n",
    "        self.classIdx = classIdx\n",
    "        self.layerName = layerName\n",
    "        # if the layer name is None, attempt to automatically find\n",
    "        # the target output layer\n",
    "        if self.layerName is None:\n",
    "            self.layerName = self.find_target_layer()\n",
    "\n",
    "    def find_target_layer(self):\n",
    "        # attempt to find the final convolutional layer in the network\n",
    "        # by looping over the layers of the network in reverse order\n",
    "        for layer in reversed(self.model.layers):\n",
    "            # check to see if the layer has a 4D output\n",
    "            if len(layer.output_shape) == 4:\n",
    "                return layer.name\n",
    "        # otherwise, we could not find a 4D layer so the GradCAM\n",
    "        # algorithm cannot be applied\n",
    "        raise ValueError(\"Could not find 4D layer. Cannot apply GradCAM.\")\n",
    "\n",
    "\n",
    "    def compute_heatmap(self, image, eps=1e-8):\n",
    "        # construct our gradient model by supplying (1) the inputs\n",
    "        # to our pre-trained model, (2) the output of the (presumably)\n",
    "        # final 4D layer in the network, and (3) the output of the\n",
    "        # softmax activations from the model\n",
    "        gradModel = Model(\n",
    "            inputs=[self.model.inputs],\n",
    "            outputs=[self.model.get_layer(self.layerName).output, self.model.output])\n",
    "\n",
    "        # record operations for automatic differentiation\n",
    "        with tf.GradientTape() as tape:\n",
    "            # cast the image tensor to a float-32 data type, pass the\n",
    "            # image through the gradient model, and grab the loss\n",
    "            # associated with the specific class index\n",
    "            inputs = tf.cast(image, tf.float32)\n",
    "            (convOutputs, predictions) = gradModel(inputs)\n",
    "            \n",
    "            loss = predictions[:, tf.argmax(predictions[0])]\n",
    "    \n",
    "        # use automatic differentiation to compute the gradients\n",
    "        grads = tape.gradient(loss, convOutputs)\n",
    "\n",
    "        # compute the guided gradients\n",
    "        castConvOutputs = tf.cast(convOutputs > 0, \"float32\")\n",
    "        castGrads = tf.cast(grads > 0, \"float32\")\n",
    "        guidedGrads = castConvOutputs * castGrads * grads\n",
    "        # the convolution and guided gradients have a batch dimension\n",
    "        # (which we don't need) so let's grab the volume itself and\n",
    "        # discard the batch\n",
    "        convOutputs = convOutputs[0]\n",
    "        guidedGrads = guidedGrads[0]\n",
    "\n",
    "        # compute the average of the gradient values, and using them\n",
    "        # as weights, compute the ponderation of the filters with\n",
    "        # respect to the weights\n",
    "        weights = tf.reduce_mean(guidedGrads, axis=(0, 1))\n",
    "        cam = tf.reduce_sum(tf.multiply(weights, convOutputs), axis=-1)\n",
    "\n",
    "        # grab the spatial dimensions of the input image and resize\n",
    "        # the output class activation map to match the input image\n",
    "        # dimensions\n",
    "        (w, h) = (image.shape[2], image.shape[1])\n",
    "        heatmap = cv2.resize(cam.numpy(), (w, h))\n",
    "        # normalize the heatmap such that all values lie in the range\n",
    "        # [0, 1], scale the resulting values to the range [0, 255],\n",
    "        # and then convert to an unsigned 8-bit integer\n",
    "        numer = heatmap - np.min(heatmap)\n",
    "        denom = (heatmap.max() - heatmap.min()) + eps\n",
    "        heatmap = numer / denom\n",
    "        heatmap = (heatmap * 255).astype(\"uint8\")\n",
    "        # return the resulting heatmap to the calling function\n",
    "        return heatmap\n",
    "\n",
    "    def overlay_heatmap(self, heatmap, image, alpha=0.5,\n",
    "                        colormap=cv2.COLORMAP_VIRIDIS):\n",
    "        # apply the supplied color map to the heatmap and then\n",
    "        # overlay the heatmap on the input image\n",
    "        heatmap = cv2.applyColorMap(heatmap, colormap)\n",
    "        output = cv2.addWeighted(image, alpha, heatmap, 1 - alpha, 0)\n",
    "        # return a 2-tuple of the color mapped heatmap and the output,\n",
    "        # overlaid image\n",
    "        return (heatmap, output)\n",
    "\n",
    "    #Prediction\n",
    "\n",
    "image = cv2.imread('../data/Yoga-82/YOGA_downloads_withoutClipart/Akarna_Dhanurasana/2.jpg')\n",
    "image = cv2.resize(image, (32, 32))\n",
    "image = image.astype('float32') / 255\n",
    "image = np.expand_dims(image, axis=0)\n",
    "\n",
    "preds = func_model.predict(image) \n",
    "i = np.argmax(preds[0])\n",
    "\n",
    "#To get the layer's name of the model\n",
    "\n",
    "for idx in range(len(func_model.layers)):\n",
    "    print(func_model.get_layer(index = idx).name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b9bdac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we picked `block5c_project_con` layer \n",
    "#Passing to GradCAM class\n",
    "\n",
    "icam = GradCAM(func_model, i, 'block5c_project_conv') \n",
    "heatmap = icam.compute_heatmap(image)\n",
    "heatmap = cv2.resize(heatmap, (32, 32))\n",
    "\n",
    "image = cv2.imread('/content/dog.jpg')\n",
    "image = cv2.resize(image, (32, 32))\n",
    "print(heatmap.shape, image.shape)\n",
    "\n",
    "(heatmap, output) = icam.overlay_heatmap(heatmap, image, alpha=0.5)\n",
    "\n",
    "#Visualization\n",
    "\n",
    "fig, ax = plt.subplots(1, 3)\n",
    "\n",
    "ax[0].imshow(heatmap)\n",
    "ax[1].imshow(image)\n",
    "ax[2].imshow(output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yoga",
   "language": "python",
   "name": "yoga"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
